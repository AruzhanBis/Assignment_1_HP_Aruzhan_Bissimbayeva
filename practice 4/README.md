# Практическая работа №4

**Тема:** Оптимизация параллельного кода на GPU с использованием различных типов памяти CUDA
**Цель:** Изучение глобальной, разделяемой и локальной памяти, а также их влияния на производительность.

---

## Задача 1. Генерация массива в глобальной памяти GPU

**Описание:**
Создание массива из 1 000 000 случайных чисел в глобальной памяти CUDA с использованием параллельного ядра.

**Компиляция и запуск в Google Colab:**

```bash
# Компилируем и запускаем
!nvcc -arch=sm_75 task1.cu -o task1 && ./task1
```

---

## Задача 2. Параллельная редукция суммы

**Описание:**
Реализация редукции суммы массива двумя способами:

* только с использованием глобальной памяти;
* с использованием комбинации глобальной и разделяемой памяти.

Проводится сравнение времени выполнения и демонстрируется ускорение при использовании shared memory.

**Компиляция и запуск:**

```bash
# Компилируем и запускаем
!nvcc -arch=sm_75 task2.cu -o task2 && ./task2
```

---

## Задача 3. Оптимизация сортировки на GPU

**Описание:**

* Сортировка пузырьком небольших подмассивов в локальной памяти (регистры);
* Хранение исходного массива в глобальной памяти;
* Слияние отсортированных подмассивов с использованием разделяемой памяти.

**Компиляция и запуск:**

```bash
# Компилируем и запускаем
!nvcc -arch=sm_75 task3.cu -o task3 && ./task3
```

---

## Задача 4. Измерение производительности для разных типов памяти

**Описание:**
Измерение времени редукции суммы для:

* глобальной памяти,
* разделяемой памяти,
* локальной памяти (регистров),

для массивов размером:

* 10 000 элементов
* 100 000 элементов
* 1 000 000 элементов

Результаты сохраняются в файл и используются для построения графиков зависимости времени от размера массива.

**Компиляция и запуск:**

```bash
# Компилируем
!nvcc -arch=sm_75 task4.cu -o task4

# Запускаем и сохраняем вывод
!./task4 > results.txt

# Просмотр результатов
!cat results.txt
```

---

## Построение графиков (в Python, Google Colab)

После выполнения `task4.cu` и получения файла `results.txt` можно построить графики:

```python
import matplotlib.pyplot as plt

sizes = [10000, 100000, 1000000]
global_t = []
shared_t = []
local_t = []

with open("results.txt") as f:
    next(f)
    for line in f:
        n, g, s, l = line.strip().split(",")
        global_t.append(float(g))
        shared_t.append(float(s))
        local_t.append(float(l))

plt.plot(sizes, global_t, marker='o', label='Global Memory')
plt.plot(sizes, shared_t, marker='o', label='Shared Memory')
plt.plot(sizes, local_t, marker='o', label='Local (Registers)')

plt.xlabel("Размер массива")
plt.ylabel("Время выполнения (мс)")
plt.title("Зависимость времени от размера массива и типа памяти CUDA")
plt.legend()
plt.grid(True)
plt.show()
```

---

## Автор проекта  
Студент: Aruzhan Bissimbayeva 

Группа: ADA-2403M

## Преподаватель  
Проверяющий: Sadvakassova Kuralay

